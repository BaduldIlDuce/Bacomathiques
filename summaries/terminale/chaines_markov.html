---
layout: default
lesson: "chaines_markov"
level: "terminale"
summary: true
permalink: "/cours/terminale/chaines-markov/resume/"
---

<section>
    <h2>Graphe pondéré et graphe probabiliste</h2>
    <section>
        <h3>Définition</h3>
        <div class="formula" data-api-v2-title="Graphe pondéré">
            <p>Un graphe est dit <strong>pondéré</strong> si chacune de ses arêtes est affecté d'un nombre positif (ou nul) que l'on appelle <strong>poids</strong>.</p>
            <p>Le poids d'une chaîne (ou d'un chemin) est la somme des poids de ses arêtes.</p>
        </div>
        <div class="formula" data-api-v2-title="Graphe probabiliste">
            <p>On appelle <strong>graphe probabiliste</strong> un graphe orienté et pondéré tel que :</p>
            <ul>
                <li>Pour chaque sommet, la somme des poids des arcs issus de ce sommet vaut $1$.</li>
                <li>Il y a au plus $1$ arrête orientée reliant chaque sommet.</li>
            </ul>
        </div>
        <p>Il peut être utile de faire l'analogie entre les graphes probabilistes et <a href="/cours/premiere/probabilites/#2-arbre-de-probabilit%C3%A9" data-api-v2-level="premiere" data-api-v2-lesson="probabilites" data-api-v2-hash="#2-arbre-de-probabilit%C3%A9">les arbres de probabilité</a> vus en classe de Première.</p>
    </section>
    <section>
        <h3>Matrice de transition</h3>
        <div class="formula" data-api-v2-title="Définition">
            <p>Soit $G$ un graphe probabiliste d'ordre $n$. On appelle <strong>matrice de transition</strong> du graphe $G$, la matrice carrée d'ordre $n$ dont le coefficient à la ligne $i$ et à la colonne $j$ est égal au poids de l'arête reliant le sommet $i$ au sommet $j$.</p>
            <p>Une telle matrice est qualifiée de <strong>stochastique</strong> car la somme des coefficients de chacune de ses lignes vaut $1$.</p>
        </div>
        <p>Attention cependant à ne pas confondre matrice de transition et matrice d'adjacence.</p>
    </section>
</section>
<section>
    <h2>Chaînes de Markov</h2>
    <section>
        <h3>Qu'est-ce qu'une chaîne de Markov ?</h3>
        <p>Il vous est fortement conseillé de relire (et de maîtriser) le cours sur <a href="/cours/terminale/variables-aleatoires-concentration-grands-nombres/" data-api-v2-level="terminale" data-api-v2-lesson="variables-aleatoires-concentration-grands-nombres">les variables aléatoires</a> avant d'aborder cette section. De plus, sachez que cette partie est sans doute la plus difficile du programme de Terminale. Mais ne vous découragez pas car elle reste parfaitement accessible !</p>
        <div class="formula" data-api-v2-title="Définition">
            <p>Soit $(X_n)$ une suite de variables aléatoires discrètes définies sur un même univers $\Omega$ et à valeurs dans un ensemble $E$. On dit que $(X_n)$ définit une <strong>chaîne de Markov</strong> sur $E$ si pour tout $n \in \mathbb{N}$ et tout $x_0, x_1, x_2, \text{ ... }, x_n \in E$, l'événement $(X_n = x_n)$ ne dépend que de l'événement antérieur $(X_{n-1} = x_{n-1})$ (et pas des précédents) ; autrement dit, si $p_{(X_{n-1} = x_{n-1}) \, \cap \text{ ... } \cap \, (X_0 = x_0)}(X_n = x_n) = p_{(X_{n-1} = x_{n-1})}(X_n = x_n)$.</p>
            <p>De plus, l'ensemble $E$ est appelé <strong>espace des états</strong> de la chaîne de Markov.</p>
        </div>
        <p>En français, cela signifie que si $X_n$ représente l'état d'un système à un temps $n$, alors l'état suivant $X_{n+1}$ ne dépend que de l'état au temps $n$ et pas des états précédents.</p>
        <p>De plus, notez bien que nous n'avons pas fait d'hypothèse sur le cardinale de $E$ (qui peut donc être de cardinal $m \in \mathbb{N}$). En classe de Terminale, nous nous limiterons principalement au cas où $E$ possède $2$ voire $3$ éléments.</p>
        <div class="formula" data-api-v2-title="Chaîne de Markov homogène">
            <p>Soit $(X_n)$ une chaîne de Markov dont on note $E$ l'espace des états. Alors $(X_n)$ est dite <strong>homogène</strong> si pour tout $n \in \mathbb{N}$ et pour tout $x$, $y \in E$, la probabilité $p_{(X_n = x)}(X_{n+1} = y)$ est indépendante de $n$.</p>
            <p>En termes mathématiques, cela signifie que pour tout $n \in \mathbb{N}$ et pour tout $x$, $y \in E$, $p_{(X_n = x)}(X_{n+1} = y) = p_{(X_0 = x)}(X_1 = y)$.</p>
        </div>
    </section>
    <section>
        <h3>Matrice et graphe associés à une chaîne de Markov</h3>
        <div class="formula" data-api-v2-title="Matrice de transition">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \{x_1, x_2, \text{ ... }, x_m\}$ l'espace des états. La <strong>matrice de transition</strong> de $(X_n)$ est la matrice carrée d'ordre $m$ dont le coefficient situé à la $i$-ième ligne et à la $j$-ième colonne est égal à $p_{i,j} = p_{(X_n = x_i)}(X_{n+1} = x_j)$.</p>
        </div>
        <div class="formula" data-api-v2-title="Graphe associé à une chaîne de Markov">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \{x_1, x_2, \text{ ... }, x_m\}$ l'espace des états. On associe à cette chaîne de Markov un graphe probabiliste $G$ d'ordre $m$ dont les sommets sont les états $x_i$ et dont les arêtes $x_i - x_j$ sont pondérées par les poids $p_{i,j} = p_{(X_n = x_i)}(X_{n+1} = x_j)$.</p>
            <p>La matrice de transition de $(X_n)$ est égale à la matrice de transition du graphe probabiliste $G$ : il s'agit donc aussi d'une matrice stochastique.</p>
        </div>
    </section>
    <section>
        <h3>Distributions dans une chaîne de Markov</h3>
        <div class="formula" data-api-v2-title="Proposition">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \{x_1, x_2, \text{ ... }, x_m\}$ l'espace des états. On pose $p_{i,j}^{(k)} = p_{(X_0 = x_i)}(X_k = x_j)$ pour tout $k \in \mathbb{N}^*$ (qui représente la probabilité que la chaîne de Markov $(X_n)$ passe de l'état $x_i$ à l'état $x_j$ en $k$ étapes). On a :</p>
            <p>$\displaystyle{p_{i,j}^{(k)} = \sum_{q=1}^m p_{i,q}^{(k-1)} \times p_{q,j}^{(1)} = p_{i,1}^{(k-1)} \times p_{1,j}^{(1)} + p_{i,2}^{(k-1)} \times p_{2,j}^{(1)} + \text{ ... } + p_{i,m}^{(k-1)} \times p_{m,j}^{(1)}}$.</p>
            <p>De plus, comme $(X_n)$ est homogène, $p_{i,j}^{(k)} = p_{i,j}^{(n+k)}$ pour tout $n \in \mathbb{N}$.</p>
        </div>
        <p>Cette formule semble un petit peu compliquée à interpréter. Elle signifie simplement que la probabilité que la chaîne de Markov $(X_n)$ passe de l'état $x_i$ à l'état $x_j$ en $k$ étapes est égale à la probabilité qu'elle passe de l'état $e_i$ à $e_q$ en une étape, puis de passer de $e_q$ à $e_j$ en $k-1$ étapes. Heureusement, il est possible de la simplifier grandement à l'aide des matrices de transition.</p>
        <div class="formula" data-api-v2-title="Lien avec la matrice de transition">
            <p>En reprenant les notations précédentes et en notant $M$ la matrice de transition de $(X_n)$, on a que $p_{i,j}^{(k)}$ est le coefficient à la ligne $i$ et à la colonne $j$ de la matrice $M^k$.</p>
        </div>
        <p>Enfin, donnons la définition centrale de cette section.</p>
        <div class="formula" data-api-v2-title="Définition">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \{x_1, x_2, \text{ ... }, x_m\}$ l'espace des états. On appelle <strong>suite des distributions</strong> de $(X_n)$ la suite de matrices $(\pi_n)$, définie pour tout $n \in \mathbb{N}$ par $\displaystyle{\pi_n = \begin{pmatrix} p(X_n = x_1) & p(X_n = x_2) & \text{ ... } & p(X_n = e_m) \end{pmatrix}}$.</p>
            <p>$\pi_n$ est donc une matrice ligne d'ordre $m$ et est appelée <strong>distribution au temps $n$</strong>.</p>
            <p>$\pi_0$ (la distribution au temps $0$) est appelée <strong>distribution initiale</strong>.</p>
        </div>
        <p>Une propriété très sympathique des distributions, est que l'on dispose d'une relation de récurrence permettant de calculer facilement la distribution à un temps $n$ donné.</p>
        <div class="formula" data-api-v2-title="Relation entre $\pi_{n+1}$ et $\pi_n$">
            <p>En reprenant les notations de la définition précédente et en notant $M$ la matrice de transition de $(X_n)$, on a que la suite $(\pi_n)$ vérifie une relation de récurrence donnée pour tout $n \in \mathbb{N}$ par $\pi_{n+1} = \pi_n M$.</p>
            <p>On en déduit que pour tout $n \in \mathbb{N}$, $\pi_n = \pi_0 M^n$.</p>
        </div>
    </section>
    <section>
        <h3>Distribution invariante</h3>
        <div class="formula" data-api-v2-title="Définition">
            <p>Soit $(X_n)$ une chaîne de Markov homogène de matrice de transition $M$. Une distribution $\pi$ est <strong>invariante</strong> si les deux conditions suivantes sont respectées :</p>
            <ul>
                <li>$\displaystyle{\pi M = \pi}$ (donc si $\pi$ est une distribution à un temps $n$, on a $\pi = \pi_n$ et cette condition se résume à avoir $\pi_n = \pi_n M = \pi_{n+1}$).</li>
                <li>La somme des coefficients de $\pi$ vaut $1$.</li>
            </ul>
        </div>
        <div class="formula" data-api-v2-title="Existence et unicité de la distribution invariante au temps $n$">
            <p>Soit $(X_n)$ une chaîne de Markov homogène de matrice de transition $M$.</p>
            <p>Si $M$ ne possède aucun coefficient non nul autre que sur sa diagonale, alors $(X_n)$ admet une unique distribution invariante $\pi$.</p>
        </div>
        <div class="formula" data-api-v2-title="Convergence de la distribution">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $(\pi_n)$ la suite des distributions.</p>
            <ul>
                <li>Si $(\pi_n)$ est une suite de matrices convergente, alors elle converge vers une distribution invariante $\pi$.</li>
                <li>Si le cardinal de l'ensemble des états de $(X_n)$ est $2$, alors $(\pi_n)$ est convergente (et converge vers la distribution invariante $\pi$).</li>
            </ul>
        </div>
    </section>
</section>
