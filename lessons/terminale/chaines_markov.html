---
layout: default
lesson: "chaines_markov"
level: "terminale"
permalink: "/cours/terminale/chaines-markov/"
---

<section>
    <h2>Graphe pondéré et graphe probabiliste</h2>
    <section>
        <h3>Définition</h3>
        <div class="formula" data-api-v2-title="Graphe pondéré">
            <p>Un graphe est dit <strong>pondéré</strong> si chacune de ses arêtes est affecté d'un nombre positif (ou nul) que l'on appelle <strong>poids</strong>.</p>
            <p>Le poids d'une chaîne (ou d'un chemin) est la somme des poids de ses arêtes.</p>
        </div>
        <div class="tip" data-api-v2-title="Exemple">
            <p>On considère le graphe orienté et pondéré suivant :</p>
            <div class="text-center">
                <img src="/assets/img/lessons/terminale/chaines_markov/graphe_1.svg" alt="Graphe 1" width="200">
            </div>
            <p>On a :</p>
            <ul>
                <li>Le poids de l'arête $A-B$ vaut $0$.</li>
                <li>Le poids du chemin $A-B-C-A-D$ vaut $0+4+2+7 = 13$.</li>
            </ul>
        </div>
        <div class="formula" data-api-v2-title="Graphe probabiliste">
            <p>On appelle <strong>graphe probabiliste</strong> un graphe orienté et pondéré tel que :</p>
            <ul>
                <li>Pour chaque sommet, la somme des poids des arcs issus de ce sommet vaut $1$.</li>
                <li>Il y a au plus $1$ arrête orientée reliant chaque sommet.</li>
            </ul>
        </div>
        <p>Il peut être utile de faire l'analogie entre les graphes probabilistes et <a href="https://bacomathiqu.es/cours/premiere/probabilites/#2-arbre-de-probabilit%C3%A9" data-api-v2-level="premiere" data-api-v2-lesson="probabilites" data-api-v2-hash="#2-arbre-de-probabilit%C3%A9">les arbres de probabilité</a> vus en classe de Première.</p>
        <div class="tip" data-api-v2-title="Exemple">
            <p>Faisons un exemple concret. On souhaite étudier l'évolution d'une maladie chez un certain individu. À un jour donné, cet individu est soit malade (que l'on note $M$), soit soigné (que l'on note $S$). On suppose que pour cette maladie :</p>
            <ul>
                <li>La probabilité qu'une personne malade guérisse le lendemain est $0,4$.</li>
                <li>La probabilité qu'une personne saine tombe malade le lendemain est $0,1$.</li>
            </ul>
            <p>Le graphe probabiliste modélisant cette situation est le graphe $G$ suivant :</p>
            <div class="text-center">
                <img src="/assets/img/lessons/terminale/chaines_markov/graphe_2.svg" alt="Graphe 2" width="220">
            </div>
            <p>On remarque que la somme des poids des arêtes issues du sommet $S$ vaut $0,9+0,1 = 1$ (idem pour $M$ qui vaut $0,6+0,4 = 1$).</p>
        </div>
    </section>
    <section>
        <h3>Matrice de transition</h3>
        <div class="formula" data-api-v2-title="Définition">
            <p>Soit $G$ un graphe probabiliste d'ordre $n$. On appelle <strong>matrice de transition</strong> du graphe $G$, la matrice carrée d'ordre $n$ dont le coefficient à la ligne $i$ et à la colonne $j$ est égal au poids de l'arête reliant le sommet $i$ au sommet $j$.</p>
            <p>Une telle matrice est qualifiée de <strong>stochastique</strong> car la somme des coefficients de chacune de ses lignes vaut $1$.</p>
        </div>
        <div class="tip" data-api-v2-title="Exemple">
            <p>Dans l'exemple précédent (en supposant que $S$ est le 1<sup>er</sup> sommet et que $M$ est le 2<sup>ème</sup>) la matrice de transition du graphe $G$ est $\displaystyle{\begin{pmatrix} 0,9 & 0,1 \\ 0,4 & 0,6 \end{pmatrix}}$.</p>
        </div>
        <p>Attention cependant à ne pas confondre matrice de transition et matrice d'adjacence.</p>
    </section>
</section>
<section>
    <h2>Chaînes de Markov</h2>
    <section>
        <h3>Qu'est-ce qu'une chaîne de Markov ?</h3>
        <p>Il vous est fortement conseillé de relire (et de maîtriser) le cours sur <a href="https://bacomathiqu.es/cours/terminale/variables-aleatoires-concentration-grands-nombres/" data-api-v2-level="terminale" data-api-v2-lesson="variables-aleatoires-concentration-grands-nombres">les variables aléatoires</a> avant d'aborder cette section. De plus, sachez que cette partie est sans doute la plus difficile du programme de Terminale. Mais ne vous découragez pas car elle reste parfaitement accessible !</p>
        <div class="formula" data-api-v2-title="Définition">
            <p>Soit $(X_n)$ une suite de variables aléatoires discrètes définies sur un même univers $\Omega$ et à valeurs dans un ensemble $E$. On dit que $(X_n)$ définit une <strong>chaîne de Markov</strong> sur $E$ si pour tout $n \in \mathbb{N}$ et tout $x_0, x_1, x_2, \text{ ... }, x_n \in E$, l'événement $(X_n = x_n)$ ne dépend que de l'événement antérieur $(X_{n-1} = x_{n-1})$ (et pas des précédents) ; autrement dit, si $p_{(X_{n-1} = x_{n-1}) \, \cap \text{ ... } \cap \, (X_0 = x_0)}(X_n = x_n) = p_{(X_{n-1} = x_{n-1})}(X_n = x_n)$.</p>
            <p>De plus, l'ensemble $E$ est appelé <strong>espace des états</strong> de la chaîne de Markov.</p>
        </div>
        <p>En français, cela signifie que si $X_n$ représente l'état d'un système à un temps $n$, alors l'état suivant $X_{n+1}$ ne dépend que de l'état au temps $n$ et pas des états précédents.</p>
        <p>De plus, notez bien que nous n'avons pas fait d'hypothèse sur le cardinale de $E$ (qui peut donc être de cardinal $m \in \mathbb{N}$). En classe de Terminale, nous nous limiterons principalement au cas où $E$ possède $2$ voire $3$ éléments, mais nous allons quand-même voir très bientôt un exemple de chaîne de Markov à $12$ états.</p>
        <div class="tip" data-api-v2-title="Variable aléatoire discrète">
            <p>Une variable aléatoire $X$ définie sur un univers $\Omega$ est dite <strong>discrète</strong> si $X(\Omega)$ est un ensemble dénombrable.</p>
        </div>
        <div class="formula" data-api-v2-title="Chaîne de Markov homogène">
            <p>Soit $(X_n)$ une chaîne de Markov dont on note $E$ l'espace des états. Alors $(X_n)$ est dite <strong>homogène</strong> si pour tout $n \in \mathbb{N}$ et pour tout $x$, $y \in E$, la probabilité $p_{(X_n = x)}(X_{n+1} = y)$ est indépendante de $n$.</p>
            <p>En termes mathématiques, cela signifie que pour tout $n \in \mathbb{N}$ et pour tout $x$, $y \in E$, $p_{(X_n = x)}(X_{n+1} = y) = p_{(X_0 = x)}(X_1 = y)$.</p>
        </div>
        <div class="tip" data-api-v2-title="Exemple">
            <p>Eliott fait la collection des vignettes des 11 joueurs titulaires de l'Équipe de France de football qu'il trouve dans des paquets de céréales. À chaque fois qu'il achète un paquet, il a donc une probabilité de $\frac{1}{11}$ de tomber sur le $k$-ième joueur (pour tout $k$ compris entre $1$ et $11$).</p>
            <p>Si on note par $X_n$ le nombre de vignettes différentes dans la collection d'Eliott après qu'il ait ouvert $n$ paquets de céréales, on a que $(X_n)$ est une chaîne de Markov homogène (commençant par $X_0 = 0$). En effet, pour tout $k \in \{0, 1, \text{ ... }, 11\}$, on a que l'événement $(X_{n+1} = k)$ ne dépend que de $X_n$ :</p>
            <p>$\displaystyle{p_{A}(X_{n+1} = k) = \begin{cases} 1 \text{ si } k = 11 \text{ et si }  A \text{ est l'événement } (X_n = 11) \\ \frac{10}{11} \text{ si } k \neq 11 \text{ et si } A \text{ est l'événement } (X_n = k) \\ \frac{1}{11} \text{ si } A \text{ est l'événement } (X_n = k-1) \\ 0 \text{ sinon} \end{cases}}$</p>
            <p>Pour détailler un peu plus :</p>
            <ul>
                <li>Si on a $(X_n = 11)$, alors Eliott a déjà sa collection complète. Donc la probabilité que sa collection reste complète est égale à $1$.</li>
                <li>Si on a $(X_n = k)$, alors on la probabilité d'avoir $(X_{n+1} = k)$ est égale à la probabilité de ne pas tirer de nouveau joueur (qui est $1 - \frac{1}{11} = \frac{10}{11}$).</li>
                <li>Si on a $(X_n = k-1)$, alors on la probabilité d'avoir $(X_{n+1} = k)$ est égale à la probabilité de tirer un nouveau joueur (qui est $\frac{1}{11}$).</li>
                <li>Sinon, comme on ne peut pas tirer deux nouveaux joueurs d'un coup ou en enlever un de la collection, la probabilité d'avoir $(X_{n+1} = k)$ est égale à $0$.</li>
                <li>Notons de plus que $(X_n)$ est homogène car le calcul de $p(X_{n+1} = k)$ est indépendant de $n$ (mais reste dépendant de $X_n$, attention).</li>
            </ul>
            <p>De plus, on a que l'espace des états $E$ est $\{0, 1, \text{ ... }, 11\}$.</p>
            <p>Cet exemple est très connu et porte un nom : il s'agit du <strong>problème du collectionneur de vignettes</strong>. Pour votre culture, sachez qu'en moyenne, il faudra ouvrir environ $n \ln(n)$ paquets de céréales pour compléter une collection de $n$ vignettes.</p>
        </div>
    </section>
    <section>
        <h3>Matrice et graphe associés à une chaîne de Markov</h3>
        <div class="formula" data-api-v2-title="Matrice de transition">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \{x_1, x_2, \text{ ... }, x_m\}$ l'espace des états. La <strong>matrice de transition</strong> de $(X_n)$ est la matrice carrée d'ordre $m$ dont le coefficient situé à la $i$-ième ligne et à la $j$-ième colonne est égal à $p_{i,j} = p_{(X_n = x_i)}(X_{n+1} = x_j)$.</p>
        </div>
        <div class="tip">
            <p>Comme cette probabilité est indépendant de $n$, on peut tout-à-fait prendre $n = 0$ dans la définition. On a alors $p_{i,j} = p_{(X_0 = x_i)}(X_1 = x_j)$.</p>
        </div>
        <div class="formula" data-api-v2-title="Graphe associé à une chaîne de Markov">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \{x_1, x_2, \text{ ... }, x_m\}$ l'espace des états. On associe à cette chaîne de Markov un graphe probabiliste $G$ d'ordre $m$ dont les sommets sont les états $x_i$ et dont les arêtes $x_i - x_j$ sont pondérées par les poids $p_{i,j} = p_{(X_n = x_i)}(X_{n+1} = x_j)$.</p>
            <p>La matrice de transition de $(X_n)$ est égale à la matrice de transition du graphe probabiliste $G$ : il s'agit donc aussi d'une matrice stochastique.</p>
        </div>
        <div class="tip" data-api-v2-title="Exemple">
            <p>Reprenons l'exemple précédent. Alors la matrice de transition associée à $(X_n)$ est la matrice $M \in \mathcal{M}_{12}(\mathbb{R})$ :</p>
            <p>$M = \displaystyle{\begin{pmatrix} \frac{10}{11} & \frac{1}{11} & 0 & \text{...} & 0 & 0 \\ 0 & \frac{10}{11} & \frac{1}{11} & \text{...} & 0 & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\ 0 & 0 & 0 & \text{...} & \frac{10}{11} & \frac{1}{11} \\ 0 & 0 & 0 & \text{...} & 0 & 1 \\ \end{pmatrix}}$
            <p>Et le graphe associé à $(X_n)$ est le graphe probabiliste d'ordre $12$ :</p>
            <div class="text-center">
                <img src="/assets/img/lessons/terminale/chaines_markov/graphe_3.svg" alt="Graphe 3" width="500">
            </div>
        </div>
    </section>
    <section>
        <h3>Distributions dans une chaîne de Markov</h3>
        <div class="formula" data-api-v2-title="Proposition">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \{x_1, x_2, \text{ ... }, x_m\}$ l'espace des états. On pose $p_{i,j}^{(k)} = p_{(X_0 = x_i)}(X_k = x_j)$ pour tout $k \in \mathbb{N}^*$ (qui représente la probabilité que la chaîne de Markov $(X_n)$ passe de l'état $x_i$ à l'état $x_j$ en $k$ étapes). On a :</p>
            <p>$\displaystyle{p_{i,j}^{(k)} = \sum_{q=1}^m p_{i,q}^{(k-1)} \times p_{q,j}^{(1)} = p_{i,1}^{(k-1)} \times p_{1,j}^{(1)} + p_{i,2}^{(k-1)} \times p_{2,j}^{(1)} + \text{ ... } + p_{i,m}^{(k-1)} \times p_{m,j}^{(1)}}$.</p>
            <p>De plus, comme $(X_n)$ est homogène, $p_{i,j}^{(k)} = p_{i,j}^{(n+k)}$ pour tout $n \in \mathbb{N}$.</p>
        </div>
        <div class="proof" data-api-v2-title="Proposition">
            <p>$\displaystyle{p_{i,j}^{(k)} = p_{(X_0 = x_i)}(X_k = x_j)}$</p>
            <p>$\displaystyle{= \sum_{q=1}^m p_{(X_0 = x_i)}((X_k = x_j) \, \cap \, (X_{k-1} = x_q))}$</p>
            <p>$\displaystyle{= \sum_{q=1}^m p_{(X_{k-1} = x_q) \, \cap \, (x_0 = x_i)}(X_k = x_j) p_{(X_0 = x_i)}(X_{k-1} = x_q)}$ (par la formule des probabilités totales)</p>
            <p>$\displaystyle{= \sum_{q=1}^m p_{(X_{k-1} = x_q)}(X_k = x_j) p_{(X_0 = x_i)}(X_{k-1} = x_q)}$</p>
            <p>$\displaystyle{= \sum_{q=1}^m p_{(X_0 = x_q)}(X_1 = x_j) p_{(X_0 = x_i)}(X_{k-1} = x_q)}$ (par homogénéité)</p>
            <p>$\displaystyle{= \sum_{q=1}^m p_{j,q}^{(1)} \times p_{i,q}^{(k-1)}}$.</p>
        </div>
        <p>Cette formule semble un petit peu compliquée à interpréter. Elle signifie simplement que la probabilité que la chaîne de Markov $(X_n)$ passe de l'état $x_i$ à l'état $x_j$ en $k$ étapes est égale à la probabilité qu'elle passe de l'état $e_i$ à $e_q$ en une étape, puis de passer de $e_q$ à $e_j$ en $k-1$ étapes. Heureusement, il est possible de la simplifier grandement à l'aide des matrices de transition.</p>
        <div class="formula" data-api-v2-title="Lien avec la matrice de transition">
            <p>En reprenant les notations précédentes et en notant $M$ la matrice de transition de $(X_n)$, on a que $p_{i,j}^{(k)}$ est le coefficient à la ligne $i$ et à la colonne $j$ de la matrice $M^k$.</p>
        </div>
        <p>Enfin, donnons la définition centrale de cette section.</p>
        <div class="formula" data-api-v2-title="Définition">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \{x_1, x_2, \text{ ... }, x_m\}$ l'espace des états. On appelle <strong>suite des distributions</strong> de $(X_n)$ la suite de matrices $(\pi_n)$, définie pour tout $n \in \mathbb{N}$ par $\displaystyle{\pi_n = \begin{pmatrix} p(X_n = x_1) & p(X_n = x_2) & \text{ ... } & p(X_n = e_m) \end{pmatrix}}$.</p>
            <p>$\pi_n$ est donc une matrice ligne d'ordre $m$ et est appelée <strong>distribution au temps $n$</strong>.</p>
            <p>$\pi_0$ (la distribution au temps $0$) est appelée <strong>distribution initiale</strong>.</p>
        </div>
        <p>Une propriété très sympathique des distributions, est que l'on dispose d'une relation de récurrence permettant de calculer facilement la distribution à un temps $n$ donné.</p>
        <div class="formula" data-api-v2-title="Relation entre $\pi_{n+1}$ et $\pi_n$">
            <p>En reprenant les notations de la définition précédente et en notant $M$ la matrice de transition de $(X_n)$, on a que la suite $(\pi_n)$ vérifie une relation de récurrence donnée pour tout $n \in \mathbb{N}$ par $\pi_{n+1} = \pi_n M$.</p>
            <p>On en déduit que pour tout $n \in \mathbb{N}$, $\pi_n = \pi_0 M^n$.</p>
        </div>
        <div class="proof" data-api-v2-title="Relation entre $\pi_{n+1}$ et $\pi_n$">
            <p>Soit $n \in \mathbb{N}$. Les événements $(X_n = x_1), (X_n = x_2), \text{ ... }, (X_n =x_m)$ partitionnent (recouvrent) notre univers, donc par la formule des probabilités totales appliquée à notre système complet d'événements et à $(X_{n+1} = x_j)$ :</p>
            <p>$p(X_{n+1} = x_j) = p((X_{n+1} = x_j) \, \cap \, (X_n = x_1)) + \text{ ... } + p((X_{n+1} = x_j) \, \cap \, (X_n = x_m))$</p>
            <p>$= p_{(X_n = x_1)}(X_{n+1} = x_j) \times p(X_n = x_1) + \text{ ... } + p_{(X_n = x_m)}(X_{n+1} = x_j) \times (X_n = x_m)$</p>
            <p>$= \pi_n M$</p>
            <p>Et la formule $\pi_n = \pi_0 M^n$ se déduit de la formule d'une suite géométrique (où $M$ serait <q>la raison</q> et $\pi_0$ le premier terme).</p>
        </div>
        <div class="tip" data-api-v2-title="Exemple">
            <p>Intéressons nous à l'alimentation d'un chat durant la journée. Il dispose de trois gamelles différentes $L$, $C$ et $P$ dans lesquelles se trouvent respectivement du lait, des croquettes et de la pâté.</p>
            <p>On suppose que le chat a commencé sa journée par du lait et que toutes les heures, il se dirige vers une des gamelles suivant le graphe probabiliste ci-dessous :</p>
            <div class="text-center">
                <img src="/assets/img/lessons/terminale/chaines_markov/graphe_4.svg" alt="Graphe 4" width="300">
            </div>
            <p>On note par $X_n$ la variable aléatoire qui donne la gamelle qu'a choisi le chat à la $n$-ième heure. On a donc que $(X_n)$ est une chaîne de Markov homogène dont l'espace des états est $E = \{L; C; P\}$. Si on note $(\pi_n)$ la suite des distributions de $(X_n)$, on a alors que $\pi_0 = \begin{pmatrix} 1 & 0 & 0 \end{pmatrix}$.</p>
            <p>Soit $M$ la matrice de transition $M$ de $(X_n)$. Calculons quelques puissances de $M$ :</p>
            <ul>
                <li>$\displaystyle{M = \begin{pmatrix} 0,5 & 0,3 & 0,2 \\ 0,2 & 0,7 & 0,1 \\ 0,3 & 0,3 & 0,4 \end{pmatrix}}$</li>
                <li>$\displaystyle{M^2 = \begin{pmatrix} 0,37 & 0,42 & 0,21 \\ 0,27 & 0,58 & 0,15 \\ 0,33 & 0,42 & 0,25 \end{pmatrix}}$</li>
                <li>$\displaystyle{M^3 = \begin{pmatrix} 0,332 & 0,468 & 0,2 \\ 0,296 & 0,532 & 0,172 \\ 0,324 & 0,468 & 0,208 \end{pmatrix}}$</li>
            </ul>
            <p>Ainsi :</p>
            <ul>
                <li>$\pi_1 = \pi_0 M = \begin{pmatrix} 0,5 & 0,3 & 0,2 \end{pmatrix}$</li>
                <li>$\pi_2 = \pi_0 M^2 = \begin{pmatrix} 0,37 & 0,42 & 0,21 \end{pmatrix}$</li>
                <li>$\pi_3 = \pi_0 M^3 = \begin{pmatrix} 0,332 & 0,468 & 0,2 \end{pmatrix}$</li>
            </ul>
            <p>Et par exemple $p_{1,2}^{(3)} = 0,468$ : la probabilité que le chat passe à sa gamelle de croquettes 3 heures après le lait est d'environ 47%.</p>
        </div>
    </section>
    <section>
        <h3>Distribution invariante</h3>
        <div class="formula" data-api-v2-title="Définition">
            <p>Soit $(X_n)$ une chaîne de Markov homogène de matrice de transition $M$. Une distribution $\pi$ est <strong>invariante</strong> si les deux conditions suivantes sont respectées :</p>
            <ul>
                <li>$\displaystyle{\pi M = \pi}$ (donc si $\pi$ est une distribution à un temps $n$, on a $\pi = \pi_n$ et cette condition se résume à avoir $\pi_n = \pi_n M = \pi_{n+1}$).</li>
                <li>La somme des coefficients de $\pi$ vaut $1$.</li>
            </ul>
        </div>
        <div class="formula" data-api-v2-title="Existence et unicité de la distribution invariante au temps $n$">
            <p>Soit $(X_n)$ une chaîne de Markov homogène de matrice de transition $M$.</p>
            <p>Si $M$ ne possède aucun coefficient non nul autre que sur sa diagonale, alors $(X_n)$ admet une unique distribution invariante $\pi$.</p>
        </div>
        <div class="formula" data-api-v2-title="Convergence de la distribution">
            <p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $(\pi_n)$ la suite des distributions.</p>
            <ul>
                <li>Si $(\pi_n)$ est une suite de matrices convergente, alors elle converge vers une distribution invariante $\pi$.</li>
                <li>Si le cardinal de l'ensemble des états de $(X_n)$ est $2$, alors $(\pi_n)$ est convergente (et converge vers la distribution invariante $\pi$).</li>
            </ul>
        </div>
        <div class="tip" data-api-v2-title="Exemple">
            <p>Reprenons l'exemple précédent et voyons si $(X_n)$ admet une distribution invariante.</p>
            <p>Remarquons tout d'abord que la matrice de transition $M$ ne possède aucun coefficient non nul. Donc $(X_n)$ admet une unique distribution invariante $\pi$.</p>
            <p>Posons donc $\pi = \begin{pmatrix} x & y & z \end{pmatrix}$ et déterminons $x$, $y$ et $z$ :</p>
            <p>On doit avoir $\pi M = \pi$</p>
            <p>$\iff \begin{pmatrix} x & y & z \end{pmatrix} \begin{pmatrix} 0,5 & 0,3 & 0,2 \\ 0,2 & 0,7 & 0,1 \\ 0,3 & 0,3 & 0,4 \end{pmatrix} = \begin{pmatrix} x & y & z \end{pmatrix}$</p>
            <p>$\iff \begin{pmatrix} 0,5x + 0,2y + 0,3z & 0,3x + 0,7y + 0,3z & 0,2x + 0,1y + 0,4z \end{pmatrix} = \begin{pmatrix} x & y & z \end{pmatrix}$</p>
            <p>$\iff \begin{cases} \frac{1}{2}x + \frac{1}{5}y + \frac{3}{10}z = x \\ \frac{3}{10}x + \frac{7}{10}y + \frac{3}{10}z = y \\ \frac{1}{5}x + \frac{1}{10}y + \frac{2}{5}z = z \end{cases}$ (en passant en écriture fractionnaire)</p>
            <p>$\iff \begin{cases} -\frac{1}{2}x + \frac{1}{5}y + \frac{3}{10}z = 0 \\ \frac{3}{10}x - \frac{3}{10}y + \frac{3}{10}z = 0 \\ \frac{1}{5}x + \frac{1}{10}y - \frac{3}{5}z = 0 \end{cases}$</p>
            <p>$\iff \begin{cases} x = \frac{2}{5}y + \frac{3}{5}z \\ -\frac{9}{50}y + \frac{12}{25}z = 0 \\ \frac{9}{50}y - \frac{12}{25}z = 0 \end{cases}$</p>
            <p>$\iff \begin{cases} x = \frac{2}{5} \times \frac{8}{3} z + \frac{3}{5}z = \frac{5}{3}z \\ y = \frac{50}{9} \times \frac{12}{25}z = \frac{8}{3}z \end{cases}$</p>
            <p>Donc $\pi$ est de la forme $\pi = \begin{pmatrix} \frac{5}{3}z & \frac{8}{3}z & z \end{pmatrix}$. De plus, la somme des coefficients de $\pi$ doit faire $1$, donc :</p>
            <p>$\frac{5}{3}z + \frac{8}{3}z + z = 1 \iff \frac{16}{3}z = 1 \iff z = \frac{3}{16}$.</p>
            <p>Donc l'unique distribution invariante $\pi$ de $(X_n)$ est $\pi = \begin{pmatrix} \frac{5}{16} & \frac{1}{2} & \frac{3}{16} \end{pmatrix} = \begin{pmatrix} 0,3125 & 0,5 & 0,1875 \end{pmatrix}$.</p>
        </div>
    </section>
</section>